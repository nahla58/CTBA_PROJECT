# ü§ó Configuration Hugging Face pour CTBA Platform

## ‚úÖ √âtapes Rapides (5 minutes)

### 1. Cr√©er un compte Hugging Face (GRATUIT)
- Allez sur: https://huggingface.co/join
- Cr√©ez votre compte (email + mot de passe)

### 2. G√©n√©rer une cl√© API (GRATUIT)
- Connectez-vous sur: https://huggingface.co/settings/tokens
- Cliquez sur **"New token"**
- Nom du token: `CTBA Platform`
- Type: **Read** (suffisant pour l'Inference API)
- Cliquez sur **"Generate a token"**
- **COPIEZ la cl√©** (commence par `hf_...`)

### 3. Configurer CTBA Platform

#### Option A: Fichier `.env` (Recommand√©)
```bash
cd backend
cp .env.example .env
```

√âditez `.env` et ajoutez:
```env
AI_PROVIDER=huggingface
HUGGINGFACE_API_KEY=hf_VotreCl√©Ici...
HUGGINGFACE_MODEL=mistral-7b
```

#### Option B: Variable d'environnement PowerShell
```powershell
$env:AI_PROVIDER="huggingface"
$env:HUGGINGFACE_API_KEY="hf_VotreCl√©Ici..."
$env:HUGGINGFACE_MODEL="mistral-7b"
```

### 4. Red√©marrer le backend
```powershell
cd backend
python main.py
```

---

## üéØ Mod√®les Disponibles (tous GRATUITS)

| Mod√®le | Description | Cas d'usage |
|--------|-------------|-------------|
| **mistral-7b** ‚≠ê | Mistral 7B Instruct v0.2 | **Recommand√©** - Excellent fran√ßais, rapide |
| **mixtral-8x7b** üöÄ | Mixtral 8x7B Instruct | Tr√®s puissant, plus lent |
| **zephyr-7b** ‚ö° | Zephyr 7B Beta | Rapide et efficace |
| **llama2-7b** ü¶ô | Meta Llama 2 7B Chat | Classique et fiable |
| **openchat** üí¨ | OpenChat 3.5 | Conversationnel |

Pour changer de mod√®le:
```env
HUGGINGFACE_MODEL=mixtral-8x7b
```

---

## üí∞ Limites Gratuites

### Inference API (Gratuit)
- ‚úÖ **Aucun co√ªt**
- ‚úÖ Rate limit raisonnable (suffisant pour usage normal)
- ‚è±Ô∏è Premi√®re requ√™te peut prendre 20-30s (chargement du mod√®le)
- ‚ö° Requ√™tes suivantes: ~2-5s

### Si vous d√©passez les limites
Options:
1. **Attendre quelques minutes** (les quotas se r√©initialisent)
2. **Passer √† Hugging Face Pro** ($9/mois, limites plus √©lev√©es)
3. **Utiliser fallback temporaire** (Simple AI templates)

---

## üîß D√©pannage

### ‚ùå Erreur: "Invalid API key"
- V√©rifiez que la cl√© commence par `hf_`
- R√©g√©n√©rez une nouvelle cl√© sur https://huggingface.co/settings/tokens

### ‚ùå Erreur 503: "Model is loading"
- C'est normal pour la premi√®re requ√™te
- Le syst√®me attend automatiquement (20-30s)
- R√©essayez si timeout

### ‚ùå Erreur 429: "Rate limit exceeded"
- Attendez 5-10 minutes
- Les quotas se r√©initialisent automatiquement
- OU configurez temporairement: `AI_PROVIDER=simple`

### ‚ùå R√©ponse vide ou incompl√®te
- Changez de mod√®le: `HUGGINGFACE_MODEL=zephyr-7b`
- Le syst√®me utilise automatiquement un fallback de qualit√©

---

## üìä Comparaison avec OpenRouter

| Crit√®re | Hugging Face | OpenRouter |
|---------|--------------|------------|
| **Co√ªt** | ‚úÖ GRATUIT | ‚ùå Payant ($) |
| **Quotas** | ‚úÖ G√©n√©reux | ‚ö†Ô∏è Par token |
| **Latence** | ‚è±Ô∏è 2-5s | ‚ö° 1-2s |
| **Qualit√©** | ‚úÖ Excellente | ‚úÖ Excellente |
| **Setup** | üü¢ Simple | üü¢ Simple |

**Verdict**: Hugging Face est **parfait pour CTBA** (gratuit, qualit√© √©quivalente)

---

## ‚ú® Test Rapide

```powershell
# V√©rifier la configuration
cd backend
python -c "import os; from dotenv import load_dotenv; load_dotenv('.env'); print('API Key:', os.getenv('HUGGINGFACE_API_KEY')[:10] + '...' if os.getenv('HUGGINGFACE_API_KEY') else 'NOT SET')"

# Tester une rem√©diation
curl -X POST "http://localhost:8000/api/ai/remediation/CVE-2024-1234"

# V√©rifier le statut IA
curl "http://localhost:8000/api/ai/status"
```

**R√©sultat attendu**:
```json
{
  "status": "ready",
  "provider": "Hugging Face",
  "model": "mistral-7b",
  "cost": "FREE"
}
```

---

## üéì Ressources

- Documentation Hugging Face: https://huggingface.co/docs/api-inference/
- Mod√®les disponibles: https://huggingface.co/models?pipeline_tag=text-generation
- Dashboard API: https://huggingface.co/settings/tokens

---

**üí° Besoin d'aide ?**
V√©rifiez les logs du backend pour les messages d'erreur d√©taill√©s.
